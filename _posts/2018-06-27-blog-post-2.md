---
title: "What is a confidence interval?"
author: "Ben Buzzee"
permalink: /posts/2018/06/blog-post-2/
date: "June 26, 2018"
output: html_document
---

Modern introductory statistics classes tend to focus exclusively on frequentist style confidence intervals and hypothesis tests. As many new (and veteran) students of statistics know, these methods can be confusing and difficult to interpret. This post is an attempt to piece together a conceptually cogent picture of some ~~introductory~~ rather convoluted statistical ideas.

Frequentist style confidence intervals are a mainstay of nearly every introductory statistics course in the United States. This "introductory" topic is widely misunderstood and misinterpreted, even by professional scientists. So why are they so popular? And what are they really? Are there any better alternatives?

Motivation:

 * "The reason students have problems understanding hypothesis
tests is that they may be trying to think." - The Insignificance of Statistical Significance Testing

* "Example number one: the confidence interval. Its definition is so con-
trived and anti-intuitive that it's no wonder that students have difficulties
ingesting it." -William Briggs


 * "Confidence intervals are useful mainly because we can misinterpret them as probability statements about unknown parameters." -Quora Answer (from a user with a PhD in statistics from Stanford)

 * "Claims that confidence intervals yield an
index of precision, that the values within them are plausible,
and that the confidence coefficient can be read as
a measure of certainty that the interval contains the true
value, are all fallacies and unjustified by confidence interval
theory." - The fallacy of placing confidence in confidence intervals


# Frequentist Framework

To make any sense of the following statistical ideas, it is essential to clearly define what is meant by "probability." Frequentist style statistics defines the probability of an event as the relative frequency of that event as the number of trials tends towards infinity. To make a probabilistic claim, it must be set up in the context of theoretical long-run frequencies. This is the definition typically used in an introductory statistics class.

## Confidence Intervals 


### Definition
In recent times, hypothesis tests and p-values have fallen out of favor, and some (including my own past professors) have suggested confidence intervals as a superior alternative. So what are confidence intervals?

Definition (Confidence Interval): 
> An X% confidence interval for a parameter theta is an interval (L,U) generated
by a procedure that in repeated sampling has an X% probability
of containing the true value of theta (Neyman, 1937).

An interval ___generated by a procedure that___ as the number of samples tends to infinity has a 95% probability of containing the true value of the parameter. So the probability is associated with the procedure, and this probability _tends_ towards the confidence level as the sampling process is repeated.  We cannot make any probabilistic claims about the one interval we created--only the process under the scenario of repeated sampling.


### Interpretation
A great analogy: You have a rubber ball and a large plastic bowl. The ball represents a parameter and the bowl represents the confidence region. The natural (and incorrect) interpretation is to state that when tossing the ball, there is a 95% chance it lands in the bowl. The correct interpretation requires the ball be fixed on the ground, and if we toss the bowl repeatedly, the percentage of time the bowl lands on the ball tends towards 95% as the number of tosses increases.

>The confidence interval is the answer to the request: "Give me an interval that will bracket the true value of the parameter in 100p% of the instances of an experiment that is repeated a large number of times." The credible interval is an answer to the request: "Give me an interval that brackets the true value with probability p given the particular sample I've actually observed."

So is a confidence interval only useful when an experiment can be/is repeated a large number of times? Or are the theoretical properties enough to ensure confidence intervals are useful even when only one experiment is plausible?


### Other Properties
Other than provide an interval with the aforementioned property, what else do CIs tell us? Do they:
* provide a sense of variability of the estimate?
* provide a range of plausible values?



### Problems with confidence intervals
 * Definition lends itself to misinterpretation & confusion
 * Answering the wrong question?






https://www.quora.com/How-can-I-deeply-understand-statistics

Quora 1:
> Here are some questions to develop deeper understanding of statistics (I may keep adding to this if I think of more):
 * Under what circumstances, if any, does it make sense to follow the convention of fixing probability of Type I error and maximizing power subject to that constraint?
 * Under what circumstances, if any, is a confidence interval a "reasonable range of values" for an unknown parameter?
 * Why was the word "confidence" introduced into statistical practice? What does it convey that "probability" does not?
 * Is it better to draw weak conclusions with weak assumptions (non-parametric methods) or strong conclusions with strong assumptions (Bayesian methods)?
  * Why are asymptotic results useful, given that real data is always finite?
  * What are the pros and cons of using an arbitrary p-value cutoff like 0.05 to decide whether research should be published?
  * If I analyze data from a clinical trial using a non-parametric test based on randomization of treatment assignments only, can I draw any conclusions about the effectiveness of the treatment in the full population? On what basis?
  * Under what circumstances should I do a one-tailed test versus a two-tailed test?
  * What, if anything, is so great about unbiasedness? -Michael Hochster



https://stats.stackexchange.com/questions/26450/why-does-a-95-confidence-interval-ci-not-imply-a-95-chance-of-containing-the/26457#26457
https://stats.stackexchange.com/questions/11609/clarification-on-interpreting-confidence-intervals

Quora 2:
> I think the fundamental problem is that frequentist statistics can only assign a probability to something that can have a long run frequency. Whether the true value of a parameter lies in a particular interval or not doesn't have a long run frequency, becuase we can only perform the experiment once, so you can't assign a frequentist probability to it. The problem arises from the definition of a probability. If you change the definition of a probability to a Bayesian one, then the problem instantly dissapears as you are no longer tied to discussion of long run frequencies.

> See my (rather tounge in cheek) answer to a related question here:

> "A Frequentist is someone that believes probabilies represent long run frequencies with which events ocurr; if needs be, he will invent a fictitious population from which your particular situation could be considered a random sample so that he can meaningfully talk about long run frequencies. If you ask him a question about a particular situation, he will not give a direct answer, but instead make a statement about this (possibly imaginary) population."

> In the case of a confidence interval, the question we normally would like to ask (unless we have a problem in quality control for example) is "given this sample of data, return the smallest interval that contains the true value of the parameter with probability X". However a frequentist can't do this as the experiment is only performed once and so there are no long run frequencies that can be used to assign a probability. So instead the frequentist has to invent a population of experiments (that you didn't perform) from which the experiment you did perform can be considered a random sample. The frequentist then gives you an indirect answer about that fictitious population of experiments, rather than a direct answer to the question you really wanted to ask about a particular experiment.
> Essentially it is a problem of language, the frequentist definition of a popuation simply doesn't allow discussion of the probability of the true value of a parameter lying in a particular interval. That doesn't mean frequentist statistics are bad, or not useful, but it is important to know the limitations.

