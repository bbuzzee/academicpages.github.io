---
title: "The Fundemental Confidence Fallacy"
author: "Ben Buzzee"
permalink: /posts/2018/06/blog-post-2/
date: "June 26, 2018"
fontsize: 14pt
output: html_document
---

Modern introductory statistics classes tend to focus exclusively on frequentist-style confidence intervals and hypothesis tests. As the field of statistics matures, many of the shortcomings of hypothesis tests have come to light (see papers 1 and 2), leaving the confidence interval as the go-to research tool presented to new students of statistics. Although taught in virtually every introductory statistics course in the United States, confidence intervals are widely misused and misinterpreted, even by professional scientists. This post attempts to clarify exactly what a confidence interval is and how to correctly interpret them.

Motivating Quotes:

 * "Claims that confidence intervals yield an
index of precision, that the values within them are plausible,
and that the confidence coefficient can be read as
a measure of certainty that the interval contains the true
value, are all fallacies and unjustified by confidence interval
theory." - The Fallacy of Placing Confidence in Confidence Intervals




# The Problem

The need for interval estimation arises when a researcher is interested in knowing the value of an important quantity that describes an entire population (a parameter), and, for one reason or another, the entire population cannot be measured. Thus the researcher must rely on a sample to estimate the value of the parameter. The problem, then, is that different samples typically produce different estimates of the parameter of interest. The solution is to create an interval that somehow takes into account our uncertainty in a quantifiable manner.

In 1937, Jerzy Neyman published his classic paper that lays the foundation for confidence interval theory. In it, he recommends a three step procedure: 1. collect a sample, 2. create the interval (using methodology laid out in the paper) and 3. claim the value of the parameter is in the interval.

He goes on to say:

> The justification of this recommendation lies in the fact that the three steps
described are equivalent to a random experiment which may result either in a correct
or in an erroneous statement concerning the value of [the parameter], the probability of a correct
statement being equal to .99. Thus the statistician following the above recommendation
is in a position comparable with that of a game of chance with the
probability of winning being equal to .99.

And so, according to Neyman, we do our study, create our interval, and claim the parameter is contained in the interval. The probability we "win," or that our claim is correct, is equal to our confidence level. And so the problem of coherently quantitifying the uncertainty involved with estimating a parameter is solved... right? 

Unfortunately, Neyman is a master of subtle convolution that leads to technically valid statements but a terribly misled reader. The first 10 times you read the above passage, unless you are a well trained statistician, you are (probably) not correctly interpreting the subtleties employed by Neyman.

The natural interpretation of the above passage--that we can create a confidence interval, make the claim that our interval contains the parameter, and be correct with .99 probability is __NOT__ what the above passage says. We will get to the correct interpretation a bit later.

The issues with the above passage are a microcosm of all the problems with confidence intervals. They are difficult to (correctly) understand, it is natural and easy to misinterpret them as the thing we actually desire, and they are mathematically valid. Further, it is often inconsequential to misinterpet them in the way we are naturally inclined to do. Together with decades of indoctrination and arguably being the "best" option for many of those decades, and we end up where we are today. A substandard statistical method being the cornerstone of every highschool and college statistics program in the United States.

I would argue that confidence intervals are not what most people think they are. Scientists, statisticians, and researchers want an interval they can claim the parameter is in with a known level of certainty. They want to make the claim the parameter is in __the interval we created__ and know the probability of being correct.


# Frequentist Probabilities

Confidence intervals are inextricably tied to the frequentist definition of probability.

### Introduction to Confidence Intervals


#### Beginnings

The confidence intervals of today were originally developed by Jerzy Neyman in his 1937 paper "Outline of a Theory of Statistical Estimation Based on the Classical Theory of Probability." This is the same Jerzy Neyman that worked with Egon Pearson over the course of the previous several years to develop the theory behind frequentist style hypothesis testing. https://ww2.amstat.org/about/statisticiansinhistory/index.cfm?fuseaction=biosinfo&BioID=11

The work of Neyman and Pearson developed into the foundations of modern statistics. Their work was the most mathematically sound approach to statistics available at the time, and it was analytically tractable in an pre-computing era. Thus it became widely adopted and cemented into nearly every statistics curriculum in the United States.

As their methods were ingrained in the generations of new scientists and put to use, weaknesses of their approach started to surface. These weaknesses were not mathematical, and did not invalidate any of their work. The weaknesses dealt with something less tangible -- philosophy, interpretations, and a widespread lack of understanding.


### Definition(s)


To make any sense of confidence intervals, it is essential to clearly define what is meant by "probability." Frequentist style statistics defines the probability of an event as the relative frequency of that event, as the number of trials tends towards infinity. To make a probabilistic claim, it must be set up in the context of theoretical long-run frequencies. This is the definition typically used in an introductory statistics class--whether students (or even the teacher!) know it.

Definition (Confidence Interval): 
> An X% confidence interval for a parameter theta is an interval (L,U) generated
by a procedure that in repeated sampling has an X% probability
of containing the true value of theta (Neyman, 1937).

This definition leads to some natural questions:

* Is the probability associated with __a procedure under repeated sampling__ scientifically relevant?
* What is meant by repeated sampling? Two samples? Infinite samples? What about the all-important one sample we have in front of us?
* Do we have any level of certainty the parameter is in the interval?





# Back to Quote

Neyman is talking about the whole process - not the interval. The whole process is akin to a game of chance, with frequentist probability of .99. Is this acceptable?: the probability the interval brackts the parameter .99?


### Interpretation

A useful analogy: You have a tennis ball and a large plastic bowl. The ball represents the parameter(s) of interest and the bowl represents the confidence region. When we create a 95% confidence interval, the natural (and incorrect) interpretation is to assume that when the ball is tossed, there is a 95% chance it lands in the bowl. The correct interpretation requires the ball be fixed on the ground, and if we toss the bowl repeatedly, the percentage of time the bowl lands and covers the ball tends towards 95% as the bowl is repeatedly tossed.

If we toss the bowl once (create one frequentist confidence interval), the bowl either captured the ball or did not. We cannot make any probabilistic claims about the ball being in the bowl. We can state that __ if we tossed the bowl many times, __ the frequency with which the bowl lands and covers the ball will tend toward .95. The .95 probability only has meaning in the context of many bowl tosses.

Now suppose we are in the position of making a major decision based on a single confidence interval. Is the fact that a 95% long-run coverage procedure was used to create the interval relevant to our single-interval scenario? Can we just assume the probability the parameter is in the interval is 95%?


What we would really like to know is:

What is the probability the bowl covers the ball if we were only to toss the bowl once?



### Conclusion

If, as part of your research, you are making the request: 

> "Give me an interval that will bracket the true value of the parameter in 100p% of the instances of an experiment that is repeated a large number of times."

Then a frequentist style confidence interval is the appropriate solution to that request. Arguably, however, that is not in-line with what many (most) researchers are seeking when it comes to estimating parameters.


# The Bayesian Alternative: Credible Intervals

### The Bayesian way of Thinking

* Based on properties of posterior distributions.
* Only became popular when computing and MCMC allowed posteriors to be adequately described.

### Definition

* Probability as a degree of belief

>"The credible interval is an answer to the request: "Give me an interval that brackets the true value with probability p given the particular sample I've actually observed."


### Other Properties
Other than provide an interval with the aforementioned property, what else do CIs tell us? Do they:
* provide a sense of variability of the estimate?
* provide a range of plausible values?



### Problems with confidence intervals
 * Definition lends itself to misinterpretation & confusion
 * Answering the wrong question?







https://www.quora.com/How-can-I-deeply-understand-statistics

Quora 1:
> Here are some questions to develop deeper understanding of statistics (I may keep adding to this if I think of more):
 * Under what circumstances, if any, does it make sense to follow the convention of fixing probability of Type I error and maximizing power subject to that constraint?
 * Under what circumstances, if any, is a confidence interval a "reasonable range of values" for an unknown parameter?
 * Why was the word "confidence" introduced into statistical practice? What does it convey that "probability" does not?
 * Is it better to draw weak conclusions with weak assumptions (non-parametric methods) or strong conclusions with strong assumptions (Bayesian methods)?
  * Why are asymptotic results useful, given that real data is always finite?
  * What are the pros and cons of using an arbitrary p-value cutoff like 0.05 to decide whether research should be published?
  * If I analyze data from a clinical trial using a non-parametric test based on randomization of treatment assignments only, can I draw any conclusions about the effectiveness of the treatment in the full population? On what basis?
  * Under what circumstances should I do a one-tailed test versus a two-tailed test?
  * What, if anything, is so great about unbiasedness? -Michael Hochster



https://stats.stackexchange.com/questions/26450/why-does-a-95-confidence-interval-ci-not-imply-a-95-chance-of-containing-the/26457#26457
https://stats.stackexchange.com/questions/11609/clarification-on-interpreting-confidence-intervals

Quora 2:
> I think the fundamental problem is that frequentist statistics can only assign a probability to something that can have a long run frequency. Whether the true value of a parameter lies in a particular interval or not doesn't have a long run frequency, becuase we can only perform the experiment once, so you can't assign a frequentist probability to it. The problem arises from the definition of a probability. If you change the definition of a probability to a Bayesian one, then the problem instantly dissapears as you are no longer tied to discussion of long run frequencies.

> See my (rather tounge in cheek) answer to a related question here:

> "A Frequentist is someone that believes probabilies represent long run frequencies with which events ocurr; if needs be, he will invent a fictitious population from which your particular situation could be considered a random sample so that he can meaningfully talk about long run frequencies. If you ask him a question about a particular situation, he will not give a direct answer, but instead make a statement about this (possibly imaginary) population."

> In the case of a confidence interval, the question we normally would like to ask (unless we have a problem in quality control for example) is "given this sample of data, return the smallest interval that contains the true value of the parameter with probability X". However a frequentist can't do this as the experiment is only performed once and so there are no long run frequencies that can be used to assign a probability. So instead the frequentist has to invent a population of experiments (that you didn't perform) from which the experiment you did perform can be considered a random sample. The frequentist then gives you an indirect answer about that fictitious population of experiments, rather than a direct answer to the question you really wanted to ask about a particular experiment.
> Essentially it is a problem of language, the frequentist definition of a popuation simply doesn't allow discussion of the probability of the true value of a parameter lying in a particular interval. That doesn't mean frequentist statistics are bad, or not useful, but it is important to know the limitations.


# SOURCES

1. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5540883/
2. https://www.jstor.org/stable/3802789?seq=1#page_scan_tab_contents
3. https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4742490/
